gcc-12.2.0 loaded successful
cuda-11.8.0 loaded successful
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).
  from pandas.core import (
Loading cached split indices for dataset at /home/share/huadjyin/home/weiyilin/project/DNALLM/datasets/tokenized_datasets/seq_dataset/hyenadna/CD8_expression_5K/train/cache-67c10577d82440ee.arrow and /home/share/huadjyin/home/weiyilin/project/DNALLM/datasets/tokenized_datasets/seq_dataset/hyenadna/CD8_expression_5K/train/cache-e13dffe3ff20bbe0.arrow
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if not hasattr(tensorboard, "__version__") or LooseVersion(
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ) < LooseVersion("1.15"):
[WARNING|trainer.py:577] 2024-06-30 21:16:32,719 >> max_steps is given, it will override any value given in num_train_epochs
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if not hasattr(tensorboard, "__version__") or LooseVersion(
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ) < LooseVersion("1.15"):
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  if not hasattr(tensorboard, "__version__") or LooseVersion(
/home/share/huadjyin/home/baiyong01/.local/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  ) < LooseVersion("1.15"):
[WARNING|trainer.py:577] 2024-06-30 21:16:54,989 >> max_steps is given, it will override any value given in num_train_epochs
[WARNING|trainer.py:577] 2024-06-30 21:16:55,004 >> max_steps is given, it will override any value given in num_train_epochs
[INFO|trainer.py:2048] 2024-06-30 21:16:55,379 >> ***** Running training *****
[INFO|trainer.py:2049] 2024-06-30 21:16:55,379 >>   Num examples = 121,595,120
[INFO|trainer.py:2050] 2024-06-30 21:16:55,380 >>   Num Epochs = 1
[INFO|trainer.py:2051] 2024-06-30 21:16:55,380 >>   Instantaneous batch size per device = 72
[INFO|trainer.py:2054] 2024-06-30 21:16:55,380 >>   Total train batch size (w. parallel, distributed & accumulation) = 864
[INFO|trainer.py:2055] 2024-06-30 21:16:55,380 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:2056] 2024-06-30 21:16:55,380 >>   Total optimization steps = 60,000
[INFO|trainer.py:2057] 2024-06-30 21:16:55,380 >>   Number of trainable parameters = 1,576,961
[WARNING|modeling_utils.py:1188] 2024-06-30 21:17:12,252 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1188] 2024-06-30 21:17:12,265 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[WARNING|modeling_utils.py:1188] 2024-06-30 21:17:12,392 >> Could not estimate the number of tokens of the input, floating-point operations will not be computed
[INFO|trainer.py:3614] 2024-06-30 21:18:28,490 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-06-30 21:18:28,490 >>   Num examples = 24324
[INFO|trainer.py:3619] 2024-06-30 21:18:28,490 >>   Batch size = 72
[INFO|trainer.py:3614] 2024-06-30 21:20:19,804 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-06-30 21:20:19,806 >>   Num examples = 24324
[INFO|trainer.py:3619] 2024-06-30 21:20:19,806 >>   Batch size = 72
[INFO|trainer.py:3614] 2024-06-30 21:22:08,009 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-06-30 21:22:08,009 >>   Num examples = 24324
[INFO|trainer.py:3619] 2024-06-30 21:22:08,009 >>   Batch size = 72
[INFO|trainer.py:3614] 2024-06-30 21:23:53,772 >> ***** Running Evaluation *****
[INFO|trainer.py:3616] 2024-06-30 21:23:53,774 >>   Num examples = 24324
[INFO|trainer.py:3619] 2024-06-30 21:23:53,774 >>   Batch size = 72
WARNING:torch.distributed.elastic.agent.server.api:Received 15 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2823566 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2823567 closing signal SIGTERM
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2823568 closing signal SIGTERM
